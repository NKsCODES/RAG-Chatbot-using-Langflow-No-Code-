# RAG-Based LLM Application

## Project Overview

This project demonstrates building a Retrieval Augmented Generation (RAG) based LLM application. It leverages Langflow, a no-code tool, to create a chatbot that can answer questions from a PDF document and maintain conversation history.

## Features

* **Question Answering:** Answers questions based on content from a provided PDF.
* **RAG Architecture:** Employs Retrieval Augmented Generation to improve the accuracy and relevance of answers.
* **Conversational History:** Maintains context across multiple turns of conversation.
* **No-Code Implementation:** Built using Langflow, requiring minimal to no coding.

## Technologies Used

* Langflow (for building the RAG pipeline)
* Large Language Model (LLM) - Specific model not detailed in the video description.
* PDF document (as the knowledge source)

## Setup

Since this project utilizes a no-code tool (Langflow), the setup involves:

1.  Installing and configuring Langflow (refer to Langflow's documentation for specific instructions).
2.  Importing the provided Langflow workflow (if available).
3.  Specifying the PDF document to be used as the knowledge source.

## Usage

1.  Run the Langflow application.
2.  Interact with the chatbot interface.
3.  Ask questions related to the content of the loaded PDF document.

## Potential Enhancements

* Exploring different LLMs for improved performance.
* Adding support for multiple document types.
* Implementing more sophisticated retrieval strategies.
* Customizing the chatbot's appearance and behavior.
* Integrating with external data sources.
